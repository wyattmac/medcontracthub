#!/usr/bin/env tsx
/**
 * Test User Journey Monitoring System
 * Quick validation that monitoring works correctly
 */

import { createUserJourneyMonitor, CRITICAL_JOURNEYS } from '../lib/monitoring/user-journey-monitor'

async function testMonitoring() {
  console.log('ğŸ§ª Testing User Journey Monitoring System...\n')

  const baseUrl = process.env.E2E_BASE_URL || 'http://localhost:3000'
  console.log(`ğŸ“ Testing against: ${baseUrl}\n`)

  const monitor = createUserJourneyMonitor()

  // Test each journey
  for (const journey of CRITICAL_JOURNEYS) {
    console.log(`ğŸ” Testing journey: ${journey.name}`)
    console.log(`   ğŸ“ ${journey.description}`)
    
    try {
      const result = await monitor.executeJourney(journey)
      
      if (result.success) {
        console.log(`   âœ… PASSED (${result.totalTime}ms)`)
        
        // Show performance details
        for (const step of result.stepResults) {
          const icon = step.performanceScore === 'good' ? 'ğŸŸ¢' : 
                      step.performanceScore === 'needs-improvement' ? 'ğŸŸ¡' : 'ğŸ”´'
          console.log(`     ${icon} ${step.stepName}: ${step.responseTime}ms`)
        }
      } else {
        console.log(`   âŒ FAILED: ${result.error}`)
        
        // Show failure details
        for (const step of result.stepResults) {
          if (!step.success) {
            console.log(`     ğŸ’¥ ${step.stepName}: ${step.error}`)
          }
        }
      }
    } catch (error) {
      console.log(`   ğŸ’¥ ERROR: ${error}`)
    }
    
    console.log('') // Empty line for readability
  }

  console.log('ğŸ¯ Monitoring test complete!')
}

// Run the test
testMonitoring().catch(console.error)